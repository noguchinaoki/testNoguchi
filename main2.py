import os
import streamlit as st
import psycopg2
from openai import AzureOpenAI
import re
import pandas as pd

# PostgreSQLæ¥ç¶šæƒ…å ±ï¼ˆé©å®œå¤‰æ›´ï¼‰
conn = psycopg2.connect(
    host="localhost",
    dbname="unipa",
    user="unipauser",
    password="unipauser",
    port=5433
)

# # --- Azure OpenAI è¨­å®š ---
# azure_endpoint = os.environ["CHATBOT_AZURE_OPENAI_ENDPOINT"]
# api_key = os.environ["CHATBOT_AZURE_OPENAI_API_KEY"]
# deployment_name = "gpt-4.1-nano"
# api_version = "2024-12-01-preview"

# client = AzureOpenAI(
#     azure_endpoint=azure_endpoint,
#     api_key=api_key,
#     api_version=api_version
# )

# # --- PostgreSQL æ¥ç¶šæƒ…å ± ---
# DB_HOST = "localhost"
# DB_NAME = "unipa"
# DB_USER = "unipauser"
# DB_PASS = "unipauser"

# # --- ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®åˆæœŸåŒ– ---
# if "chat_history" not in st.session_state:
#     st.session_state.chat_history = []

# def generate_sql_from_question(question):
# #     system_message_sql = [{
# #         "role": "system",
# #         "content": """
# # ã‚ãªãŸã¯PostgreSQLã®SQLã‚¯ã‚¨ãƒªã‚’ç”Ÿæˆã™ã‚‹ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
# # ä»¥ä¸‹ã®ãƒ†ãƒ¼ãƒ–ãƒ«æ§‹é€ ã¨é–¢ä¿‚æ€§ã‚’å‰æã¨ã—ã¦ãã ã•ã„ï¼š

# # pkb_cmps(campus_no,campus_name)
# # pkb_class_sbt(class_sbt_cd,class_sbt_name)

# # ä»¥ä¸‹ã®ãƒ«ãƒ¼ãƒ«ã«å¾“ã£ã¦ãã ã•ã„ï¼š
# # è³ªå•ã«å¿œã˜ã¦ SELECT, UPDATE, DELETE, INSERT ãªã©é©åˆ‡ãªSQLã‚’ç”Ÿæˆã—ã¦ãã ã•ã„
# # SQLæ–‡ã®ã¿ã‚’è¿”ã—ã¦ãã ã•ã„(èª¬æ˜ã‚„è£œè¶³ã¯ä¸è¦)
# # ã€Œsqlã€ãªã©ã®ãƒ©ãƒ™ãƒ«ã¯ä»˜ã‘ãªã„ã§ãã ã•ã„
# # 1æ–‡ã§å®Œçµã•ã›ã¦ãã ã•ã„
# # """
# #     }]
#     system_message_sql = [{
#         "role": "system",
#         "content": """
# You are an assistant that generates PostgreSQL SQL queries.

# Assume the following table schemas:
# pkb_cmps(campus_no, campus_name)
# pkb_class_sbt(class_sbt_cd, class_sbt_name)

# Rules:
# - Generate appropriate SQL (SELECT, UPDATE, DELETE, INSERT) based on the user's question.
# - Return only the SQL query (no explanation, no labels).
# - Use a single SQL statement.
# """
#         }]

#     user_message = [{"role": "user", "content": question}]
#     response = client.chat.completions.create(
#         model=deployment_name,
#         messages=system_message_sql + user_message,
#         stream=False
#     )

#     raw_sql = response.choices[0].message.content.strip()
#     raw_sql = re.sub(r"(?i)^sql\s*\n?", "", raw_sql).strip()

#     if not raw_sql or raw_sql.lower() == "undefined" or not re.search(r"\b(select|update|insert|delete)\b", raw_sql.lower()):
#         return None

#     return raw_sql

# # --- SQLå®Ÿè¡Œé–¢æ•°ï¼ˆå…¨SQLå¯¾å¿œï¼‰ ---
# def run_sql(sql):
#     try:
#         conn = psycopg2.connect(
#             host=DB_HOST,
#             port=5433,
#             dbname=DB_NAME,
#             user=DB_USER,
#             password=DB_PASS,
#             sslmode="disable"
#         )
#         cur = conn.cursor()
#         cur.execute(sql.strip())

#         if sql.strip().lower().startswith("select"):
#             rows = cur.fetchall()
#             result_text = "\n".join("ãƒ»" + "ï½œ".join(str(x) for x in row) for row in rows)
#         else:
#             conn.commit()
#             result_text = f"âœ… SQLå®Ÿè¡ŒæˆåŠŸï¼š{cur.rowcount}ä»¶å‡¦ç†ã•ã‚Œã¾ã—ãŸ"

#         cur.close()
#         conn.close()
#         return result_text
#     except Exception as e:
#         return f"SQLå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}"

# # --- é€šå¸¸å¿œç­”é–¢æ•°ï¼ˆstream=Trueï¼‰ ---
# def get_response(prompt: str = ""):
#     st.session_state.chat_history.append({"role": "user", "content": prompt})
#     system_message = [{"role": "system", "content": "You are a helpful assistant."}]
#     chat_messages = [{"role": m["role"], "content": m["content"]} for m in st.session_state.chat_history]
#     response = client.chat.completions.create(
#         model=deployment_name,
#         messages=system_message + chat_messages,
#         stream=True
#     )
#     return response

# # --- å¿œç­”å±¥æ­´è¿½åŠ é–¢æ•° ---
# def add_history(response):
#     st.session_state.chat_history.append({"role": "assistant", "content": response})

# # --- ã‚¿ã‚¤ãƒˆãƒ«è¡¨ç¤º ---
# st.title("å­¦ç”Ÿãƒ‡ãƒ¼ã‚¿ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ")

# # --- ãƒãƒ£ãƒƒãƒˆå±¥æ­´è¡¨ç¤ºï¼ˆã™ã¹ã¦ã®å±¥æ­´ã‚’æç”»ï¼‰ ---
# for chat in st.session_state.chat_history:
#     with st.chat_message(chat["role"]):
#         st.markdown(chat["content"])

# # --- å…¥åŠ›ã¨å¿œç­”å‡¦ç† ---
# if prompt := st.chat_input("è³ªå•ã‚’ã©ã†ãï¼ˆä¾‹ï¼šã‚­ãƒ£ãƒ³ãƒ‘ã‚¹ãƒ†ãƒ¼ãƒ–ãƒ«ã«ã¤ã„ã¦withã‚¯ãƒ©ã‚¹ç¨®åˆ¥ï¼‰"):
#     st.session_state.chat_history.append({"role": "user", "content": prompt})
#     with st.chat_message("user"):
#         st.markdown(prompt)

#     # --- SQLç”Ÿæˆå¯¾è±¡ã‹ã©ã†ã‹ã‚’åˆ¤å®š ---
#     if any(keyword in prompt for keyword in ["ã‚­ãƒ£ãƒ³ãƒ‘ã‚¹"]):
#         with st.chat_message("assistant"):
#             st.markdown("SQLã‚’ç”Ÿæˆã—ã¦ã„ã¾ã™â€¦")
#             sql = generate_sql_from_question(prompt)
#             st.write("ğŸ” å®Ÿè¡Œå¯¾è±¡SQLï¼ˆreprè¡¨ç¤ºï¼‰:", repr(sql))

#             if sql is None:
#                 st.markdown("âš ï¸ SQLã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚è³ªå•å†…å®¹ã‚’è¦‹ç›´ã—ã¦ãã ã•ã„ã€‚")
#                 add_history("SQLç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
#             else:
#                 st.markdown("ç”Ÿæˆã•ã‚ŒãŸSQL:")
#                 st.code(sql, language="sql")

#                 st.markdown("SQLã‚’å®Ÿè¡Œã—ã¦ã„ã¾ã™â€¦")
#                 result_text = run_sql(sql.strip())
#                 st.markdown(result_text)
#                 add_history(result_text)
#     else:
#         response_text = ""
#         stream = get_response(prompt)
#         for chunk in stream:
#             if hasattr(chunk, "choices") and chunk.choices:
#                 delta = chunk.choices[0].delta
#                 if hasattr(delta, "content") and delta.content:
#                     response_text += delta.content
#         with st.chat_message("assistant"):
#             st.markdown(response_text)
#         add_history(response_text)

import psycopg2
import pandas as pd

# 1. å¤‰æ•°ã®å®šç¾©
A = 2009
B = 1
C = '1162'
D = 200701

# 2. kmg_sskãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰kanri_no=Aã«ä¸€è‡´ã™ã‚‹kmk_cdã‚’å–å¾—
query1 = "SELECT kmk_cd FROM kmg_ssk WHERE kanri_no = %s AND hyoka_cd < %s"
kmk_cd_df = pd.read_sql_query(query1, conn, params=(D, 'Z'))
kmk_cd_list = kmk_cd_df['kmk_cd'].tolist()

# kmk_cdãŒç©ºã®å ´åˆã®åˆ†å²
if not kmk_cd_list:
    print("kmk_cd IN () ãŒç©ºã«ãªã£ã¦ã„ã‚‹")
else:
    # 3. kmz_kmk_meisaiã¨kmb_kmk_haitoã‚’çµåˆã—ã¦ã€kmkbnr_cdã”ã¨ã«tani_suã‚’åˆè¨ˆ
    query2 = """
    SELECT h.kmkbnr_cd, SUM(m.tani_su) AS total_tani_su
    FROM kmz_kmk_meisai m
    JOIN kmb_kmk_haito h 
    ON m.kmk_cd = h.kmk_cd 
    AND m.meisai_no = h.meisai_no
    WHERE m.kmk_cd IN %s
    AND h.nyugak_nendo = %s
    AND h.gakki_no = %s
    AND h.cgks_cd = %s
    GROUP BY h.kmkbnr_cd
    """

    tani_su_df = pd.read_sql_query(query2, conn, params=(tuple(kmk_cd_list), A, B, C))

    # 4. kmb_kbrãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰æ¡ä»¶ä¸€è‡´ã™ã‚‹kmkbnr_cdã¨sot_yoken_taniã‚’å–å¾—
    query3 = """
    SELECT kmkbnr_cd, sot_yoken_tani
    FROM kmb_kbr
    WHERE nyugak_nendo = %s AND gakki_no = %s AND cgks_cd = %s AND sot_yoken_tani IS NOT NULL
    """
    sot_yoken_df = pd.read_sql_query(query3, conn, params=(A, B, C))

    # 5. tani_su_dfã«ä¸è¶³ã—ã¦ã„ã‚‹kmkbnr_cdã®ãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’è¿½åŠ ï¼ˆtotal_tani_su=0ï¼‰
    missing_kmkbnr = set(sot_yoken_df['kmkbnr_cd']) - set(tani_su_df['kmkbnr_cd'])
    missing_df = pd.DataFrame({
        'kmkbnr_cd': list(missing_kmkbnr),
        'total_tani_su': [0] * len(missing_kmkbnr)
    })
    tani_su_df = pd.concat([tani_su_df, missing_df], ignore_index=True)

    # 6. éšå±¤æ§‹é€ ã®èªè­˜ï¼ˆè¦ªå­é–¢ä¿‚ã®æ¨å®šï¼‰
    def find_parent(code, candidates):
        possible_parents = [c for c in candidates if code != c and code.startswith(c)]
        return max(possible_parents, key=len) if possible_parents else None

    sot_yoken_df['parent_kmkbnr_cd'] = sot_yoken_df['kmkbnr_cd'].apply(lambda x: find_parent(x, sot_yoken_df['kmkbnr_cd'].tolist()))
    tani_su_df['parent_kmkbnr_cd'] = tani_su_df['kmkbnr_cd'].apply(lambda x: find_parent(x, tani_su_df['kmkbnr_cd'].tolist()))

    # 7. å­ã®å˜ä½æ•°ã‚’è¦ªã«åŠ ç®—
    def aggregate_with_children(df):
        agg_df = df.copy()
        for idx, row in df.iterrows():
            parent = row['parent_kmkbnr_cd']
            if parent:
                agg_df.loc[agg_df['kmkbnr_cd'] == parent, 'total_tani_su'] += row['total_tani_su']
        return agg_df

    tani_su_df = aggregate_with_children(tani_su_df)

    # 8. tani_suã¨sot_yoken_taniã‚’kmkbnr_cdã§ãƒãƒ¼ã‚¸ã—ã¦ä¸è¶³å˜ä½æ•°ã‚’è¨ˆç®—
    merged_df = pd.merge(sot_yoken_df, tani_su_df[['kmkbnr_cd', 'total_tani_su']], on='kmkbnr_cd', how='left')
    merged_df['fusoku_tani'] = merged_df['sot_yoken_tani'] - merged_df['total_tani_su']

    # çµæœè¡¨ç¤º
    print(merged_df)